
\chapter{Zbiór danych}\label{ch:dataset}

Na potrzeby metod opisach w Rozdziale \ref{TODO} przygotowano zbiór danych składający się z zagadnień optymalizacyjnych opisanych w języku angielskim oraz referencyjnych modeli PL w języku \akronim {ZIMPL} dla tych zagadnień.
%Zbiór danych stanowią zadania treściowe z dziedziny programowania liniowego wraz z ich wynikiem zapisanym w języku \textit{ZIMPL}.
Zbiór danych zawiera 4380 przykładów. % wraz z prawidłowym kodem \textit{ZIMPL}. 
% TP: TODO: wypada podać dokładniejsze statystyki, tj. bazowych zagadnień jest mniej (podajcie ile) i dla każdego stworzono od X do Y wariantów opisu oraz wzorcowych modeli. Łacznie przykładów jest 4380.
Zbiór danych został podzielony i wykorzystany do odpowiednio: trenowania, walidacji oraz testowania programu. % TP: TODO: wg jakiego schematu podzielony?

% TP: TODO: unikajcie synonimów. Skoro zbiór danych został wprowadzony jako "zbiór danych" to niech zawsze nazywa się zbiorem danych, a nie bazą. Poprawiam, ale być może coś zostanie.
\section{Proces powstawania zbioru danych}

Proces tworzenia zbioru danych można podzielić na trzy różne etapy: etap wyszukiwania zagadnień optymalizacyjnych, etap formułowania modeli PL przy użyciu języka \textit{ZIMPL}, oraz etap zwielokrotniania przykładów za pomocą zmiany sposobu formułowania treści zadań. % TP: TODO <- niejasne: "treści zadań". Czy chodzi o "...formułowania opisów i modeli PL."?

% TP: TODO: być może warto rozrysować ten proces razem z wariantami/równoległymi ścieżkami?

\subsection{Wyszukiwanie zagadnień optymalizacyjnych}

% TP: TODO: tutaj należy opisać protokół wyszukiwania; obecnie nie wiadomo skąd się wzięły akurat takie źródła - dlaczego je wybraliście. Wybór źródeł powinien być przeprowadzony w jakiś systematyczny sposób, np. na podstawie konkretnych zapytań wrzuconych w wyszukiwarkę google scholar/scopus/web of science/google books i odfiltrowaniu wyników w usystematyzowany sposób.

Ze względu na specyfikę zbioru danych, skupiono się na przeszukaniu źródeł opisów zagadnień optymalizacyjnych zawierających sformułowania wzorcowych modeli PL.
Do źródeł tych należą publikacje, dokumentacja związana z programowaniem liniowym\cite{brilliant_linear,byjus_linear,cimt,arsdcollege2020,libretexts_linear,superprof_linear,toppr_graphical} oraz zbiorów Politechniki Poznańskiej. % TP: TODO: co to za zbiory? Jak piszecie o repo GECS, to sugeruję zamiast tego stwierdzenia dokleić wyżej cytowanie na https://www.sciencedirect.com/science/article/pii/S2210650221000572  
Głównym źródłem zagadniej optymalizacyjnych i modeli PL jest dokumentacja języka  \textit{ZIMPL} \cite{TODO}, która została napisana w formie przypominającej instrukcję. Zaczerpnięto również dane z przykładowych zadań publikowanych przez prowadzących zajęcia na Politechnice Poznańskiej. Zadania są zapisane w języku angielskim. Ich formuła jest zróżnicowana. Zadania są przedstawiane w formie długich opisów, punktowania problemu, tabelek, bądź są połączeniem tych form. Łącznie stworzono 40 unikalnych przykładów.

\subsection{Tworzenie modeli PL w języku \textit{ZIMPL}}

Dla wyszukanych i sprawdzonych modeli PL stworzono ich reprezentacje w języku \textit{ZIMPL}. %, rozwiązujące przedstawiony problem. % TP: model nic nie rozwiązuje, model opisuje zagadnienie
Każdy model PL posiada dwa różne warianty w języku  \textit{ZIMPL}. % TP: TODO: <- sugeruję tutaj wymienić te warianty chociaż z nazwy, bo wariant 2 pojawia się dopiero na kolejnej stronie.

Wariant pierwszy stosuje formułę \textbf{sztywnego programowania}. Takim kodem nazwano rozwiązanie, w którym wprowadzone wartości, takie jak liczby i parametry, są zapisane w sposób bezpośredni i statyczny. Utrudnia to wszelkie zmiany i dostosowania bez modyfikacji kodu, sprawiając, że model PL opisuje tylko jedną konkretną instancję zagadnienia. W~tym przypadku przy tworzeniu kodu  \textit{ZIMPL} należy się skupić na elementach uwzględnionych poniżej.

\begin{enumerate}
\item Deklaracja zmiennych, których dotyczy zadanie.


% TP: TODO: wpisałem Wam w preambułę konfigurację ZIMPL dla lstlisting, więc teraz możecie mieć za darmo kolorowanie kodu. Trzeba tylko nieco zmienić sposób wstawiania kodu ZIMPL. Przykład:
%\begin{lstlisting}[language=zimpl]
%set Food := {"Oatmeal", "Chicken", "Eggs", "Milk", "Pie", "Pork"};
%set Nutr := {"Energy", "Protein", "Calcium"};
%set Attr := Nutr + {"Servings", "Price"};
%param need[Nutr] := <"Energy"> 2000, <"Protein"> 55, <"Calcium"> 800;
%param data[Food * Attr] :=
%          |"Servings","Energy","Protein","Calcium","Price"|
%|"Oatmeal"|         4,     110,        4,        2,      3|
%|"Chicken"|         3,     205,       32,       12,     24|
%|"Eggs"   |         2,     160,       13,       54,     13|
%|"Milk"   |         8,     160,        8,      284,      9|
%|"Pie"    |         2,     420,        4,       22,     20|
%|"Pork"   |         2,     260,       14,       80,     19|;
%#                        (kcal)       (g)      (mg) (cents)       
%var x[<f> in Food] integer >= 0 <= data[f, "Servings"];
%minimize cost: sum <f> in Food: data[f, "Price"] * x[f];
%subto needed: 
%  forall <i> in Nutr:
%    sum <j> in Food: data[j,i] * x[j] >= need[i];
%\end{lstlisting}%


\begin{quote}
\begin{verbatim}
var <nazwa_zmiennej>: <zakres_wartości>; # Zadeklarowana zmienna
\end{verbatim}
\end{quote}

\item Zapisanie celu funkcji (minimalizacja lub maksymalizacja), wraz z podaniem konkretnych wartości liczbowych.

\begin{quote}
\begin{verbatim}
<minimize/maximize> <nazwa_funkcji>: <wyrażenie matematyczne
reprezentujące funkcję celu>; # Cel funkcji
\end{verbatim}
\end{quote}

\item Zapisanie ograniczeń przedstawionych w treści zadania za pomocą wyrażeń matematycznych.

\begin{quote}
\begin{verbatim}
subto <nazwa_ograniczenia>: <wyrażenie matematyczne deklarujące
ograniczenie>;
\end{verbatim}
\end{quote}
\end{enumerate}

Drugi sposób programowania polega na \textbf{wykorzystaniu parametrów i struktur danych}, takich jak zbiory. Pozwala to na łatwe wprowadzanie zmian, a także zwiększa elastyczność pracy z kodem  \textit{ZIMPL}. Jest to zalecany sposób modelowania zagadnień, natomiast komplikuje strukturę kodu, wymagając użycia nowych elementów. % TP: TODO <- skoro jest zalecany, to musi mieć jakieś zalety, a tutaj piszecie tylko o Wadach.
Jego wygląd jest pokazany poniżej.

\begin{enumerate}
\item Deklaracja zbiorów podanych w treści zadania.

\begin{quote}
\begin{verbatim}
set <nazwa_zbioru> := {<wartości>}; # Zbiór indeksów
\end{verbatim}
\end{quote}

\item Deklaracja wartości wejściowych parametrów, używanych jako dane pomocnicze przy określaniu stałych cech problemu.

\begin{quote}
\begin{verbatim}
param <nazwa_parametru>[<indeks> w <zbiór>] := <wartość dla każdego
elementu>; # Parametry związane z indeksem
param <nazwa_parametruo> := <wartość>; # Parametr globalny
\end{verbatim}
\end{quote}

\item Deklaracja zmiennych, których dotyczy zadanie.

\begin{quote}
\begin{verbatim}
var <nazwa_zmiennej>[<indeks> w <zbiór>]: <zakres_wartości>;
# Zmienna decyzyjna zależna od indeksów w zbiorze
\end{verbatim}
\end{quote}

\item Zapisanie celu funkcji (minimalizacja lub maksymalizacja), zależnego od ustalonych zmiennych i parametrów.

\begin{quote}
\begin{verbatim}
<minimize/maximize> <nazwa_funkcji>: <wyrażenie matematyczne
reprezentujące funkcję celu>; # Cel funkcji
\end{verbatim}
\end{quote}

\item Zapisanie ograniczeń przedstawionych w treści zadania za pomocą wyrażeń matematycznych.

\begin{quote}
\begin{verbatim}
subto <nazwa_ograniczenia>: <wyrażenie matematyczne deklarujące
ograniczenie>;
\end{verbatim}
\end{quote}
\end{enumerate}

Obie wersje kodu poprawnie rozwiązują problemy programowania liniowego. W generatorze testowane są dane dla obu możliwości rozwiązań, a każde z nich powstaje w inny sposób. % TP: TODO <- czy generator coś testuje? Tutaj jest chyba pomieszane nazewnictwo. Czy choci o proces tworzenia zbioru danych? Słowo "generować" pojawia się w kontekście problemu generowania modelu PL i metody generownia modelu PL, więc należy go unikać w innych kontekstach
Przygotowany przykład, zanim trafi do kolejnego etapu poszerzania zbioru danych, jest sprawdzany za pomocą ręcznych kalkulacji i narzędzi do automatycznego sprawdzania jakości kodu. % TP: TODO <- co to za ręczne kalkulacje? Ta procedura powinna być formalnie krok po kroku rozpisana, tak aby czytelnik mógł ją zreprodukować.
Do sprawdzania przykładów wykorzystywany jest algorytm rozwiązujący, dostarczony przez Solving Constraint Integer Programs \cite{TODO}. % TP: TODO <- wcześniej jest używana nazwa po prostu SCIP, po co ją rozwijać? Na pierwszy rzut oka nie wiadomo co to jest. Dopiero gdy przykład otrzyma status 'poprawny' i zadanie posiada rozwiązanie, może przejść do procesu zwielokrotniania. Ponadto SCIP to nie algorytm, ale oprogramowanie; w oprogramowaniu jest wiele _implementacji_ algorytmów. Algorytm != oprogramowanie. Czy nie lepiej napisać, że: "Poprawność składniowa oraz semantyczna modelu PL jest weryfikowana poprzez próbę jego rozwiązania solverem SCIP \cite{TODO}. Model PL, dla którego SCIP zwrócił rozwiązanie dopuszczalne jest uznawany za poprawny składniowo i semantycznie." Wydaje się, że brakuje fazy weryfikacji zgodności z wiedzą dziedzinową. A może to jest w tych ręcznych kalkulacjach? Nie wiadomo co to znaczy i jak dokładnie ta zgodność była weryfikowana (np. "Dwóch ekspertów niezależnie analizowało każdy model i weryfikowało czy funkcja celu, ograniczenia i zmienne odpowiadają odpowiednio celowi optymalizacji, zależnościom między modelowanym wielkościom oraz czynnikom podlegającym optymalizacji. Ponadto eksperci weryfikowali rozwiązanie optymalne modelu PL pod względem zgodności z wiedzą dziedzinową.").

\subsection{Zwielokrotnianie przygotowanych przykładów}

Posiadając przygotowane 40 unikalnych przykładów wraz z ich modelami PL w formule sztywnego i parametryzowanego programowania, należało powiększyć zbiór o przykłady podobne, lecz różniące się sformułowaniem i wynikami.

Początkowy proces polegał na tworzeniu przykładów o zbliżonej strukturze, ale z dywersyfikowaną treścią fabularną oraz danymi. Na podstawie jednego przykładu tworzone było od 5 do 10 różnych przykładów, w których przekształcana była narracja zadania, mógł zmienić się cel zadania z maksymalizacji na minimalizację i odwrotnie, a także zmieniały się dane i ich ilość. Dzięki temu, z podobnego zadania powstawały zupełnie niezależne i nowe problemy programowania liniowego. Sumarycznie utworzono 800 unikalnych zadań wraz z ich zmodyfikowanym kodem  \textit{ZIMPL}. % TP: TODO: <- Protokół zwielokrotniania mógłby być opisany bardziej algorytmicznie, nawet od punktów. Nie jest jasne kiedy i jakie modyfikacje były wykonywane. Czy to by random czy może wg jakiegoś klucza (jakiego?). Czy dochodziły np. nowe ograniczenia, zmienne? Warto w jednym miejscu wymienić (np. wypunktować) wszystie typy modyfikacji elementarnych, które wykonaliście, a dalej napisać, że zastosowano losowy wybór modyfikacji elementowanych do przykładu bazowego. Protokół zmiany opisów poniżej jest dużo lepiej opisany.

Posiadając taki zbiór danych, kolejnym etapem było stworzenie różniących się opisów. Każdy przykład był przepisywany i formułowany ponownie na jeden z pięciu sposobów.

\begin{enumerate}
\item Opis w formie punktów --- wersja przedstawiająca kluczowe informacje w podpunktach. Każdy element zadania jest krótko i konkretnie opisany. Zadanie prezentuje się czytelnie, a rozwiązujący ma jasno wyznaczone cele zadania.
\item Długi opis tekstowy --- zadanie wprowadza wartość fabularną oraz opisuje dokładnie zadanie w formie tekstowej. Dane techniczne są wplecione w narracyjny opis zadania.
\item Zwięzły opis tekstowy --- opis zwięźle przedstawiający problem w formie tekstowej. Nie zawiera opisów fabularnych, wprowadza jedynie konkretne informacje potrzebne do rozwiązania zadania.
\item Zestawienie w formie tabeli --- rozwiązanie jest prezentowane w formie tabeli/tabel, zwierających kluczowe dane potrzebne do rozwiązania zadania. Poza tabelą zawarty jest krótki opis celu.
\item Opis z strukturalnym uporządkowaniem --- elementy w opisie są rozdzielane na kategorie, tworząc łatwe przejrzyste i łatwe do analizy segmenty.
\end{enumerate}
% TP: TODO ^ Czy można bardziej konkretnie opisać te modyfikacje? To brzmi bardzo arbitralnie/subiektywnie i nieweryfikowalnie. Czy można określić konkretne warunki, które te zmodyfikowane opisy miały spełniać? Czy były nałożone jakieś wymagania pozafunkcjonalne, np. max. długość, poziom skomplikowania tekstu np. z użyciem którejś ze standardowych miar https://en.wikipedia.org/wiki/Readability#Readability_formulas

Decyzję o takim zwielokrotnianiu posiadanych podjęto z kilku powodów. Pierwszym z nich była potrzeba weryfikacji, czy stworzony model generatora kodu  \textit{ZIMPL} poradzi sobie z każdym rodzajem zadania, niezależnie od jego formuły i kolejności przekazywanych danych. Drugim kluczowym argumentem była mała dostępność do treści zagadnień optymalizacyjnych i modeli PL połączona z zapotrzebowaniem na dużą ilość danych do testów.

\section{Podział i wykorzystanie zbioru danych}

\begin{table}
\caption{Podział zbioru danych na podzbiory.}\label{tab:dataset:stats}
\centering%
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Zbiór} & \textbf{Sztywne} & \textbf{Parametryzowane} & \textbf{Razem} \\
\hline
Treningowy & 10 & 10 & 20\\
\hline
Walidacyjny & 30 & 30 & 60\\
\hline
Testowy & 2275 & 2025 & 4300\\
\hline
\textbf{Łącznie} & \textbf{2315} & \textbf{2065} & \textbf{4380}\\
\hline
\end{tabular}
\end{table}

Łącznie stworzono około 4800 przykładów zagadnień optymalizacyjnych wraz z modelami PL w języku  \textit{ZIMPL}. Po ponownej analizie zadań i automatycznym sprawdzeniu rozwiązań, zdecydowano się usunąć niekonkretne lub trudne do interpretacji przykłady, a także przykłady, dla których rozwiązanie dostarczone przez Solving Constraint Integer Programs zostało oznaczone jako `niepoprawne'. Przy takiej selekcji zadań, zbiór pomniejszył się do 4380 przykładów. Tak utworzony zbiór danych został podzielony na następujące podzbiory: treningowy, walidacyjny oraz testowy. Statystyki podzbiorów podano w Tabeli~\ref{tab:dataset:stats}. 
% TP: TODO: dość nietypowo wygląda, że zbiór testowy jest znacznie większy od treningowego i walidacyjnego (razem wziętych). To wymaga wyjaśnienia. Pewnym argumentem jest, że tutaj nie ma w zasadzie uczenia automatycznego - jedynie ręczne strojenie podpowiedzi (promptów).

\subsection{Zbiór treningowy}

Pierwszy zbiór nazwany treningowym, jest najmniejszym z utworzonych zbiorów i został wykorzystany bezpośrednio do tworzenia zapytań do dużego modelu językowego. Zbiór treningowy nie jest używany w walidacji i testach, bo model językowy posiada dokładne odpowiedzi do zawartych treści. Przykłady zostały dobrane w sposób różnorodny, tak aby jak najlepiej przedstawić DMJ oczekiwane rezultaty generacji kodu \textit{ZIMPL}. % TP: TODO: w jaki sposób została zapewniona dywersyfikacja? Czy każdy przykład pochodził od innego przykładu bazowego? W jaki sposób wybrano przykłady do zbioru treningowego? Jeśli losowo to z jakim rozkładem?

% TP: TODO: poniższy akapit jest w zasadzie o inżynierii podpowiedzi i jako taki bardziej pasuje do opisu metody (Rozdział 3) niż zbioru danych

Zbiór jest mały, aby pomieścić zawartość wszystkich przykładów w pojedynczym zapytaniu do DMJ, którego rozmiar jest ograniczony możliwościami DMJ. % TP: TODO <- napisałem wszystkich przykładów, ale dalej jest, że nie wszystkich; jednak nie jest jasne, które trafiają do jakich zapytań. Jak przykłady są dopasowane?
Nie każdy przykład ze zbioru został wykorzystany we wszystkich zapytaniach. W związku ze specyfiką tworzonego kodu, zapytania zostały podzielone na kategorie: programowanie sztywne i programowanie z parametryzacją. Do każdego z czterech różnych zapytań dotyczących programowania sztywnego % TP: TODO <- Nie wiadomo skąd się bierze liczba 4, dlaczego akurat tyle i jak te zapytania są wybierane
dodano wszystkie możliwe treści zadania programowania liniowego % TP: TODO <- chodzi o model czy o opis, bo niejasne?
wraz z elementem kodu  \textit{ZIMPL}, którego dotyczy zapytanie. Łącznie uwzględniono 10 takich zapytań. Podobnie zrealizowano zadanie dla programowania z parametryzacją. Dla każdego z sześciu zapytań, wykorzystano 10 zadań wraz z elementami kodu  \textit{ZIMPL}. % TP: TODO <- dlaczego 6 i jak zostały wybrane?

\subsection{Zbiór walidacyjny}

Do testowania działania generatora kodu  \textit{ZIMPL} wykorzystano początkowo 60 przykładów, w tym 30 przykładów programowania sztywnego i 30 przykładów programowania parametryzowanego. Przy pomocy tego zbioru sprawdzano jakość generowanego kodu  \textit{ZIMPL} oraz weryfikowano jego poprawność pod względem posiadanego rozwiązania oraz pokrycia rozwiązania z rozwiązaniem zawartym w bazie.

Zdecydowano się na taką liczbę przykładów w zbiorze ze względu na potrzebę szybkiej weryfikacji wyników. Czas generowania odpowiedzi wynosił maksymalnie 7 minut, % TP: TODO: jednej?
 co sprawiło, że można było szybko sprawdzać i naprawiać błędy w logice zapytań. Zbiór celowo zawarł w sobie połowę zadań z wynikami parametryzowanymi oraz połowę zadań z wynikami sztywno zaprogramowanymi, tak aby zapewnić poprawny wgląd do rozwiązań obu problemów. Zadania zostały wyselekcjonowane w różnorodny sposób, tak aby dać możliwie najszerszy wgląd w problemy, z jakimi może się mierzyć generator. % TP: TODO: podobny komentarz jak do zbioru treningowego: jak konkretnie te przykłady zostały wybrane; Myślę, że gdzieś tutaj można napisać, że ten zbiór był używany na etapie "ręcznej walidacji zapytań podczas prototypowania".

\subsection{Zbiór testowy}

Ostatni i zarazem największy wydzielony zbiór jest zbiorem testowym. Znajduje się w nim pozostałe 4300 przykładów, w tym 2315 przykładów sztywnego i 2065 przykładów parametryzowanego kodu. Zbiór został wykorzystany do prowadzenia wyłącznie zautomatyzowanych testów. Na jego podstawie zostały opracowane wyniki eksperymentu w Rozdziale~\ref{ch:experiment}.

Zbiór został stworzony tak, aby liczba przykładów odpowiedniego sposobu programowania była porównywalna, natomiast w procesie selekcji i usuwania przykładów ta liczba nieznacznie się zmieniła.

\section{Przechowywanie i dostępność zbioru}

W związku ze specyficznym formatowaniem zbiory są przechowywane w formie pliku arkusza kalkulacyjnego, a następnie konwertowane do pliku JSON, z którego pobierane są do wykonywania walidacji i testów generatora. Zbiór treningowy znajduje się bezpośrednio w zapytaniach do modelu językowego. Pozostałe dwa zbiory w formacie JSON znajdują się również na platformie Hugging Face\footnote{\label{fn:dataset:link}\url{https://huggingface.co/datasets/Tamiza/test_zimpl_dataset}} na licencji MIT, gdzie można je darmowo wykorzystywać. % TP: Świetnie!