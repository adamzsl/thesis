
\chapter{Zbiór danych}\label{ch:dataset}

Na potrzeby metod opisach w Rozdziale 3. przygotowano zbiór danych składający się z zagadnień optymalizacyjnych opisanych w języku angielskim oraz referencyjnych modeli PL w języku \akronim {ZIMPL} dla tych zagadnień. Zbiór danych stanowią zadania treściowe z dziedziny programowania liniowego wraz z ich wynikiem zapisanym w języku \akronim {ZIMPL}.
Zbiór danych zawiera 4380 przykładów wraz z prawidłowym kodem \akronim {ZIMPL}. Stanowi on zwielokrotnienie 40 unikalnych przykładów bazowych, stworzonych poprzez przeszukiwanie dostępnych źródeł dotyczących problemów programowania liniowego \cite{brilliant_linear,byjus_linear,cimt,arsdcollege2020,libretexts_linear,superprof_linear,toppr_graphical}. Dla każdego unikalnego przykładu zmieniono jego treść pod względem wartościu, celu oraz opisu zadania. Zachowano podobną logikę zadania. Stworzono od 8 do 12 różnych opisów zadania, w zależności od liczby danych zawartych w bazowym zadaniu. Dla każdego z tak utworzonych zadań oraz zadania bazowego na podstawie, którego zostały utworzone, zmieniono strukturę opisu problemu na 8 do 10 różnych sposobów, zapewniając możliwość testów takich samych zadań zależnie od wariantu opisu tekstowego problemu. Podane widełki wynikają z usuwania przykładów, które w swojej końcowej formie nie przedstawiały poprawnego opisu zadania, zwłaszcza pod względem zbyt małej ilości podanych danych, względem kodu, któremu odpowiadały.
% TP: TODO: wypada podać dokładniejsze statystyki, tj. bazowych zagadnień jest mniej (podajcie ile) i dla każdego stworzono od X do Y wariantów opisu oraz wzorcowych modeli. Łacznie przykładów jest 4380. - DONE
Zbiór danych podzielono i wykorzystano do odpowiednio: trenowania, walidacji oraz testowania programu. Zbiór treningowy wyselekcjonowano jako 20 przykładów pochodzących od 20 różnych zadań bazowych, wybranych tak aby pokryć jak największy obszar zróżnicowanych elementów kodu \akronim {ZIMPL}. Zbiór walidacyjny składa się z 60 wybranych losowo zwielokrotnionych przykładów, w tym 30 przykładów z odpowiedzią w formie sztywnego kodu oraz 30 przykładów kodu parametryzowanego. Tak jak w przypadku doboru zbioru treningowego, przyjęto zasadę wyboru zadań pochodzących od zróżnicowanych zadań bazowych. Zbiór testowy stanowi pozostałe 4300 przykładów wraz z kodem \akronim {ZIMPL}.  % TP: TODO: wg jakiego schematu podzielony? - DONE

% TP: TODO: unikajcie synonimów. Skoro zbiór danych został wprowadzony jako "zbiór danych" to niech zawsze nazywa się zbiorem danych, a nie bazą. Poprawiam, ale być może coś zostanie. - mam nadzieję, że DONE
\section{Proces powstawania zbioru danych}

Proces tworzenia zbioru danych można podzielić na trzy różne etapy: etap wyszukiwania zagadnień optymalizacyjnych, etap formułowania modeli PL przy użyciu języka \textit{ZIMPL}, oraz etap zwielokrotniania przykładów za pomocą zmiany sposobu formułowania opisów i modeli PL. % TP: TODO <- niejasne: "treści zadań". Czy chodzi o "...formułowania opisów i modeli PL."? - tak, DONE

% TP: TODO: być może warto rozrysować ten proces razem z wariantami/równoległymi ścieżkami?

tu będzie rysunek...


\subsection{Wyszukiwanie zagadnień optymalizacyjnych}

% TP: TODO: tutaj należy opisać protokół wyszukiwania; obecnie nie wiadomo skąd się wzięły akurat takie źródła - dlaczego je wybraliście. Wybór źródeł powinien być przeprowadzony w jakiś systematyczny sposób, np. na podstawie konkretnych zapytań wrzuconych w wyszukiwarkę google scholar/scopus/web of science/google books i odfiltrowaniu wyników w usystematyzowany sposób. - Adam x2?

Ze względu na specyfikę zbioru danych, skupiono się na przeszukaniu źródeł opisów zagadnień optymalizacyjnych zawierających sformułowania wzorcowych modeli PL.
Do źródeł tych należą publikacje, dokumentacja związana z programowaniem liniowym\cite{brilliant_linear,byjus_linear,cimt,arsdcollege2020,libretexts_linear,superprof_linear,toppr_graphical} oraz zbiorów Politechniki Poznańskiej. % TP: TODO: co to za zbiory? Jak piszecie o repo GECS, to sugeruję zamiast tego stwierdzenia dokleić wyżej cytowanie na https://www.sciencedirect.com/science/article/pii/S2210650221000572  - Adam x2?
Głównym źródłem zagadniej optymalizacyjnych i modeli PL jest dokumentacja języka  \akronim{ZIMPL} \cite{zimpl_manual}, która została napisana w formie przypominającej instrukcję. Zaczerpnięto również dane z przykładowych zadań publikowanych przez prowadzących zajęcia na Politechnice Poznańskiej. Zadania są zapisane w języku angielskim. Ich formuła jest zróżnicowana. Zadania są przedstawiane w formie długich opisów, punktowania problemu, tabelek, bądź są połączeniem tych form. Łącznie stworzono 40 unikalnych przykładów.

\subsection{Tworzenie modeli PL w języku \akronim{ZIMPL}}

Dla wyszukanych i sprawdzonych modeli PL stworzono ich reprezentacje w języku \akronim{ZIMPL} opisujące zagadnienie. %, rozwiązujące przedstawiony problem. % TP: model nic nie rozwiązuje, model opisuje zagadnienie - DONE
Każdy model PL posiada dwa różne warianty w języku  \akronim{ZIMPL}: wariant w formule programowania sztywnego oraz w formule parametryzowanej. % TP: TODO: <- sugeruję tutaj wymienić te warianty chociaż z nazwy, bo wariant 2 pojawia się dopiero na kolejnej stronie. - DONE

Wariant pierwszy stosuje formułę \textbf{sztywnego programowania}. Takim kodem nazwano rozwiązanie, w którym wprowadzone wartości, takie jak liczby i parametry, są zapisane w sposób bezpośredni i statyczny. Utrudnia to wszelkie zmiany i dostosowania bez modyfikacji kodu, sprawiając, że model PL opisuje tylko jedną konkretną instancję zagadnienia. W~tym przypadku przy tworzeniu kodu  \akronim{ZIMPL} należy się skupić na elementach uwzględnionych poniżej.

\begin{enumerate}
\item Deklaracja zmiennych, których dotyczy zadanie.


% TP: TODO: wpisałem Wam w preambułę konfigurację ZIMPL dla lstlisting, więc teraz możecie mieć za darmo kolorowanie kodu. Trzeba tylko nieco zmienić sposób wstawiania kodu ZIMPL. Przykład:
%\begin{lstlisting}[language=zimpl]
%set Food := {"Oatmeal", "Chicken", "Eggs", "Milk", "Pie", "Pork"};
%set Nutr := {"Energy", "Protein", "Calcium"};
%set Attr := Nutr + {"Servings", "Price"};
%param need[Nutr] := <"Energy"> 2000, <"Protein"> 55, <"Calcium"> 800;
%param data[Food * Attr] :=
%          |"Servings","Energy","Protein","Calcium","Price"|
%|"Oatmeal"|         4,     110,        4,        2,      3|
%|"Chicken"|         3,     205,       32,       12,     24|
%|"Eggs"   |         2,     160,       13,       54,     13|
%|"Milk"   |         8,     160,        8,      284,      9|
%|"Pie"    |         2,     420,        4,       22,     20|
%|"Pork"   |         2,     260,       14,       80,     19|;
%#                        (kcal)       (g)      (mg) (cents)       
%var x[<f> in Food] integer >= 0 <= data[f, "Servings"];
%minimize cost: sum <f> in Food: data[f, "Price"] * x[f];
%subto needed: 
%  forall <i> in Nutr:
%    sum <j> in Food: data[j,i] * x[j] >= need[i];
%\end{lstlisting}%


\begin{lstlisting}[language=zimpl]
# Zadeklarowana zmienna
var <nazwa_zmiennej>: <zakres_wartości>;
\end{lstlisting}

\item Zapisanie celu funkcji (minimalizacja lub maksymalizacja), wraz z podaniem konkretnych wartości liczbowych.

\begin{lstlisting}[language=zimpl]
# Cel funkcji
<minimize/maximize> <nazwa_funkcji>: <wyrażenie matematyczne reprezentujące
funkcję celu>;
\end{lstlisting}

\item Zapisanie ograniczeń przedstawionych w treści zadania za pomocą wyrażeń matematycznych.

\begin{lstlisting}[language=zimpl]
# Ograniczenia
subto <nazwa_ograniczenia>: <wyrażenie matematyczne deklarujące ograniczenie>;
\end{lstlisting}
\end{enumerate}

Drugi sposób programowania polega na \textbf{wykorzystaniu parametrów i struktur danych}, takich jak zbiory. Pozwala to na łatwe wprowadzanie zmian, a także zwiększa elastyczność pracy z kodem  \akronim{ZIMPL}. Jest to zalecany sposób modelowania zagadnień, natomiast komplikuje strukturę kodu, wymagając użycia nowych elementów. % TP: TODO <- skoro jest zalecany, to musi mieć jakieś zalety, a tutaj piszecie tylko o Wadach.
Jego wygląd jest pokazany poniżej.

\begin{enumerate}
\item Deklaracja zbiorów podanych w treści zadania.

\begin{lstlisting}[language=zimpl]
# Zbiór indeksów
set <nazwa_zbioru> := {<wartości>};
\end{lstlisting}

\item Deklaracja wartości wejściowych parametrów, używanych jako dane pomocnicze przy określaniu stałych cech problemu.

\begin{lstlisting}[language=zimpl]
# Parametry związane z indeksem
param <nazwa_parametru>[<indeks> w <zbiór>] := <wartość dla każdego elementu>;
# Parametr globalny
param <nazwa_parametruo> := <wartość>;
\end{lstlisting}

\item Deklaracja zmiennych, których dotyczy zadanie.

\begin{lstlisting}[language=zimpl]
# Zmienna decyzyjna zależna od indeksów w zbiorze
var <nazwa_zmiennej>[<indeks> w <zbiór>]: <zakres_wartości>;
\end{lstlisting}

\item Zapisanie celu funkcji (minimalizacja lub maksymalizacja), zależnego od ustalonych zmiennych i parametrów.

\begin{lstlisting}[language=zimpl]
# Cel funkcji
<minimize/maximize> <nazwa_funkcji>: <wyrażenie matematyczne reprezentujące
funkcję celu>;
\end{lstlisting}

\item Zapisanie ograniczeń przedstawionych w treści zadania za pomocą wyrażeń matematycznych.

\begin{lstlisting}[language=zimpl]
# Ograniczenia
subto <nazwa_ograniczenia>: <wyrażenie matematyczne deklarujące ograniczenie>;
\end{lstlisting}
\end{enumerate}

Obie wersje kodu poprawnie rozwiązują problemy programowania liniowego. W przy trenowaniu i testowaniu generatora wykorzystywane są dane uwzględniające obie możliwości rozwiązań. Przy generowaniu modelu \akronim{ZIMPL} użytkownik wybiera formułę, a następnie zależnie od jego wyboru, proces generacji przechodzi przez ciąg zapytań do DMJ, w wyniku których powstają opisane powyżej elementy kodu. % TP: TODO <- czy generator coś testuje? Tutaj jest chyba pomieszane nazewnictwo. Czy choci o proces tworzenia zbioru danych? Słowo "generować" pojawia się w kontekście problemu generowania modelu PL i metody generownia modelu PL, więc należy go unikać w innych kontekstach - DONE
Przygotowany przykład, zanim trafi do kolejnego etapu poszerzania zbioru danych, jest sprawdzany za pomocą narzędzi do automatycznego sprawdzania jakości kodu oraz ręcznej analizy jakości kodu. Poprawność składniowa oraz semantyczna modelu PL jest weryfikowana poprzez próbę jego rozwiązania solverem SCIP \cite{scip_documentation}. Model PL, dla którego SCIP zwrócił rozwiązanie dopuszczalne, jest uznawany za poprawny składniowo i semantycznie. Weryfikacja przebiegała również poprzez ręczne sprawdzanie przez dwóch niezależnych od siebie ekspertów każdego modelu i weryfikacji czy poszczególne elementy kodu odpowiadają celowi optymalizacji, zależnością między modelowanym wielkościom oraz czynnikom podlegającym optymalizacji. Ponadto eksperci weryfikowali rozwiązanie optymalne modelu PL pod względem zgodności z wiedzą dziedzinową.

% TP: TODO <- wcześniej jest używana nazwa po prostu SCIP, po co ją rozwijać? Na pierwszy rzut oka nie wiadomo co to jest. Dopiero gdy przykład otrzyma status 'poprawny' i zadanie posiada rozwiązanie, może przejść do procesu zwielokrotniania. Ponadto SCIP to nie algorytm, ale oprogramowanie; w oprogramowaniu jest wiele _implementacji_ algorytmów. Algorytm != oprogramowanie. Czy nie lepiej napisać, że: "Poprawność składniowa oraz semantyczna modelu PL jest weryfikowana poprzez próbę jego rozwiązania solverem SCIP \cite{TODO}. Model PL, dla którego SCIP zwrócił rozwiązanie dopuszczalne jest uznawany za poprawny składniowo i semantycznie." Wydaje się, że brakuje fazy weryfikacji zgodności z wiedzą dziedzinową. A może to jest w tych ręcznych kalkulacjach? Nie wiadomo co to znaczy i jak dokładnie ta zgodność była weryfikowana (np. "Dwóch ekspertów niezależnie analizowało każdy model i weryfikowało czy funkcja celu, ograniczenia i zmienne odpowiadają odpowiednio celowi optymalizacji, zależnościom między modelowanym wielkościom oraz czynnikom podlegającym optymalizacji. Ponadto eksperci weryfikowali rozwiązanie optymalne modelu PL pod względem zgodności z wiedzą dziedzinową."). - DONE

\subsection{Zwielokrotnianie przygotowanych przykładów}

Posiadając przygotowane 40 unikalnych przykładów wraz z ich modelami PL w formule sztywnego i parametryzowanego programowania, należało powiększyć zbiór o przykłady podobne, lecz różniące się sformułowaniem i wynikami.

Początkowy proces polegał na tworzeniu przykładów o zbliżonej strukturze, ale z dywersyfikowaną treścią fabularną oraz danymi. Na podstawie jednego przykładu tworzone było od 5 do 10 różnych przykładów, w których przekształcana była narracja zadania, mógł zmienić się cel zadania z maksymalizacji na minimalizację i odwrotnie, a także zmieniały się dane i ich ilość. Dzięki temu, z podobnego zadania powstawały zupełnie niezależne i nowe problemy programowania liniowego. Sumarycznie utworzono 800 unikalnych zadań wraz z ich zmodyfikowanym kodem  \textit{ZIMPL}. % TP: TODO: <- Protokół zwielokrotniania mógłby być opisany bardziej algorytmicznie, nawet od punktów. Nie jest jasne kiedy i jakie modyfikacje były wykonywane. Czy to by random czy może wg jakiegoś klucza (jakiego?). Czy dochodziły np. nowe ograniczenia, zmienne? Warto w jednym miejscu wymienić (np. wypunktować) wszystie typy modyfikacji elementarnych, które wykonaliście, a dalej napisać, że zastosowano losowy wybór modyfikacji elementowanych do przykładu bazowego. Protokół zmiany opisów poniżej jest dużo lepiej opisany.

Posiadając taki zbiór danych, kolejnym etapem było stworzenie różniących się opisów. Każdy przykład był przepisywany i formułowany ponownie na jeden z pięciu sposobów.

\begin{enumerate}
\item Opis w formie punktów --- wersja przedstawiająca kluczowe informacje w podpunktach. Każdy element zadania jest krótko i konkretnie opisany. Zadanie prezentuje się czytelnie, a rozwiązujący ma jasno wyznaczone cele zadania.
\item Długi opis tekstowy --- zadanie wprowadza wartość fabularną oraz opisuje dokładnie zadanie w formie tekstowej. Dane techniczne są wplecione w narracyjny opis zadania.
\item Zwięzły opis tekstowy --- opis zwięźle przedstawiający problem w formie tekstowej. Nie zawiera opisów fabularnych, wprowadza jedynie konkretne informacje potrzebne do rozwiązania zadania.
\item Zestawienie w formie tabeli --- rozwiązanie jest prezentowane w formie tabeli/tabel, zwierających kluczowe dane potrzebne do rozwiązania zadania. Poza tabelą zawarty jest krótki opis celu.
\item Opis z strukturalnym uporządkowaniem --- elementy w opisie są rozdzielane na kategorie, tworząc łatwe przejrzyste i łatwe do analizy segmenty.
\end{enumerate}
% TP: TODO ^ Czy można bardziej konkretnie opisać te modyfikacje? To brzmi bardzo arbitralnie/subiektywnie i nieweryfikowalnie. Czy można określić konkretne warunki, które te zmodyfikowane opisy miały spełniać? Czy były nałożone jakieś wymagania pozafunkcjonalne, np. max. długość, poziom skomplikowania tekstu np. z użyciem którejś ze standardowych miar https://en.wikipedia.org/wiki/Readability#Readability_formulas

Decyzję o takim zwielokrotnianiu posiadanych podjęto z kilku powodów. Pierwszym z nich była potrzeba weryfikacji, czy stworzony model generatora kodu  \akronim{ZIMPL} poradzi sobie z każdym rodzajem zadania, niezależnie od jego formuły i kolejności przekazywanych danych. Drugim kluczowym argumentem była mała dostępność do treści zagadnień optymalizacyjnych i modeli PL połączona z zapotrzebowaniem na dużą ilość danych do testów.

\section{Podział i wykorzystanie zbioru danych}

\begin{table}
\caption{Podział zbioru danych na podzbiory.}\label{tab:dataset:stats}
\centering%
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Zbiór} & \textbf{Sztywne} & \textbf{Parametryzowane} & \textbf{Razem} \\
\hline
Treningowy & 10 & 10 & 20\\
\hline
Walidacyjny & 30 & 30 & 60\\
\hline
Testowy & 2275 & 2025 & 4300\\
\hline
\textbf{Łącznie} & \textbf{2315} & \textbf{2065} & \textbf{4380}\\
\hline
\end{tabular}
\end{table}

Łącznie stworzono około 4800 przykładów zagadnień optymalizacyjnych wraz z modelami PL w języku  \akronim{ZIMPL}. Po ponownej analizie zadań i automatycznym sprawdzeniu rozwiązań, zdecydowano się usunąć niekonkretne lub trudne do interpretacji przykłady, a także przykłady, dla których rozwiązanie dostarczone przez Solving Constraint Integer Programs zostało oznaczone jako `niepoprawne'. Przy takiej selekcji zadań, zbiór pomniejszył się do 4380 przykładów. Tak utworzony zbiór danych został podzielony na następujące podzbiory: treningowy, walidacyjny oraz testowy. Statystyki podzbiorów podano w Tabeli~\ref{tab:dataset:stats}. 
% TP: TODO: dość nietypowo wygląda, że zbiór testowy jest znacznie większy od treningowego i walidacyjnego (razem wziętych). To wymaga wyjaśnienia. Pewnym argumentem jest, że tutaj nie ma w zasadzie uczenia automatycznego - jedynie ręczne strojenie podpowiedzi (promptów).

\subsection{Zbiór treningowy}

Pierwszy zbiór nazwany treningowym, jest najmniejszym z utworzonych zbiorów i został wykorzystany bezpośrednio do tworzenia zapytań do dużego modelu językowego. Zbiór treningowy nie jest używany w walidacji i testach, bo model językowy posiada dokładne odpowiedzi do zawartych treści. Przykłady zostały dobrane w sposób różnorodny, tak aby jak najlepiej przedstawić DMJ oczekiwane rezultaty generacji kodu \akronim{ZIMPL}. % TP: TODO: w jaki sposób została zapewniona dywersyfikacja? Czy każdy przykład pochodził od innego przykładu bazowego? W jaki sposób wybrano przykłady do zbioru treningowego? Jeśli losowo to z jakim rozkładem?

% TP: TODO: poniższy akapit jest w zasadzie o inżynierii podpowiedzi i jako taki bardziej pasuje do opisu metody (Rozdział 3) niż zbioru danych

Zbiór jest mały, aby pomieścić zawartość wszystkich przykładów w pojedynczym zapytaniu do DMJ, którego rozmiar jest ograniczony możliwościami DMJ. % TP: TODO <- napisałem wszystkich przykładów, ale dalej jest, że nie wszystkich; jednak nie jest jasne, które trafiają do jakich zapytań. Jak przykłady są dopasowane?
Nie każdy przykład ze zbioru został wykorzystany we wszystkich zapytaniach. W związku ze specyfiką tworzonego kodu, zapytania zostały podzielone na kategorie: programowanie sztywne i programowanie z parametryzacją. Do każdego z czterech różnych zapytań dotyczących programowania sztywnego % TP: TODO <- Nie wiadomo skąd się bierze liczba 4, dlaczego akurat tyle i jak te zapytania są wybierane
dodano wszystkie możliwe treści zadania programowania liniowego % TP: TODO <- chodzi o model czy o opis, bo niejasne?
wraz z elementem kodu  \akronim{ZIMPL}, którego dotyczy zapytanie. Łącznie uwzględniono 10 takich zapytań. Podobnie zrealizowano zadanie dla programowania z parametryzacją. Dla każdego z sześciu zapytań, wykorzystano 10 zadań wraz z elementami kodu  \akronim{ZIMPL}. % TP: TODO <- dlaczego 6 i jak zostały wybrane?

\subsection{Zbiór walidacyjny}

Do testowania działania generatora kodu  \akronim{ZIMPL} wykorzystano początkowo 60 przykładów, w tym 30 przykładów programowania sztywnego i 30 przykładów programowania parametryzowanego. Przy pomocy tego zbioru sprawdzano jakość generowanego kodu  \akronim{ZIMPL} oraz weryfikowano jego poprawność pod względem posiadanego rozwiązania oraz pokrycia rozwiązania z rozwiązaniem zawartym w bazie.

Zdecydowano się na taką liczbę przykładów w zbiorze ze względu na potrzebę szybkiej weryfikacji wyników. Czas generowania odpowiedzi wynosił maksymalnie 7 minut, % TP: TODO: jednej?
 co sprawiło, że można było szybko sprawdzać i naprawiać błędy w logice zapytań. Zbiór celowo zawarł w sobie połowę zadań z wynikami parametryzowanymi oraz połowę zadań z wynikami sztywno zaprogramowanymi, tak aby zapewnić poprawny wgląd do rozwiązań obu problemów. Zadania zostały wyselekcjonowane w różnorodny sposób, tak aby dać możliwie najszerszy wgląd w problemy, z jakimi może się mierzyć generator. % TP: TODO: podobny komentarz jak do zbioru treningowego: jak konkretnie te przykłady zostały wybrane; Myślę, że gdzieś tutaj można napisać, że ten zbiór był używany na etapie "ręcznej walidacji zapytań podczas prototypowania".

\subsection{Zbiór testowy}

Ostatni i zarazem największy wydzielony zbiór jest zbiorem testowym. Znajduje się w nim pozostałe 4300 przykładów, w tym 2315 przykładów sztywnego i 2065 przykładów parametryzowanego kodu. Zbiór został wykorzystany do prowadzenia wyłącznie zautomatyzowanych testów. Na jego podstawie zostały opracowane wyniki eksperymentu w Rozdziale~\ref{ch:experiment}.

Zbiór został stworzony tak, aby liczba przykładów odpowiedniego sposobu programowania była porównywalna, natomiast w procesie selekcji i usuwania przykładów ta liczba nieznacznie się zmieniła.

\section{Przechowywanie i dostępność zbioru}

W związku ze specyficznym formatowaniem zbiory są przechowywane w formie pliku arkusza kalkulacyjnego, a następnie konwertowane do pliku JSON, z którego pobierane są do wykonywania walidacji i testów generatora. Zbiór treningowy znajduje się bezpośrednio w zapytaniach do modelu językowego. Pozostałe dwa zbiory w formacie JSON znajdują się również na platformie Hugging Face\footnote{\label{fn:dataset:link}\url{https://huggingface.co/datasets/Tamiza/test_zimpl_dataset}} na licencji MIT, gdzie można je darmowo wykorzystywać. % TP: Świetnie!