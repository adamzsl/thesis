\chapter{Przegląd literatury}\label{ch:review}

\section{Generowanie modeli \textit{PL} z opisów zagadnień optymalizacyjnych}
\label{sec:optimus}
\textit{OptiMUS} \cite{ahmaditeshnizi2023optimus} jest systemem opartym o \akronim{DMJ}, który generuje modele PL w języku Python, których kod jest zgodny z API solwerów takich jak Gurobi~\cite{gurobi2023}, na podstawie opisu słownego zagadnienia w języku angielskim.
OptiMUS, w przeciwieństwie do systemu opracowanego w ramach tej pracy dyplomowej, obsługuje modele \english{mixed-integer linear programming, MILP} i stosuje wiele iteracji w~celu identyfikacji i naprawy błędów w generowanych modelach.
OptiMUS, w przypadku wygenerowania niepoprawnego modelu lub błędnego kodu, ponawia zapytanie do \akronim{DMJ}, dołączając treść wygenerowanego błędu przez solver lub kod wynikowy. Dzięki temu system może iteracyjnie poprawiać model, identyfikując i eliminując błędy wynikające z niezgodności składni, braków w ograniczeniach lub innych problemów logicznych.
Program generuje wtedy poprawiony kod --- operacja jest wykonywana do momentu uzyskania poprawnej odpowiedzi, bądź do momentu osiągnięcia maksymalnej liczby iteracji.

W pracy \cite{li2023synthesizingmixedintegerlinearprogramming} stworzono narzędzie, który automatyzuje proces tworzenia modeli \textit{MILP} z nieustrukturyzowanych problemów w języku naturalnym. W rozwiązaniu zintegrowany jest \akronim{DMJ} z technikami modelowania matematycznego. Przedstawiono tam trójfazowe podejście polegające na: i) identyfikacji zmiennych decyzyjnych, ii) klasyfikacji funkcji celu oraz ograniczeń, iii) generacja modeli. Narzędzie to  nie korzysta z \textit{DMJ} jako \textit{API} tak jak w prezentowanym rozwiązaniu, lecz przeprowadzono proces dostrajania \english{fine-tuning}, przy użyciu licznego zbioru danych.

\section{Odkrywanie modeli PL z innego rodzaju danych}
\akronim{GECS} (Grammatical Evolution for Constraint Synthesis)  \cite{pawlak2021grammatical} to algorytm syntezy ograniczeń dla \akronim{MILP} z przykładów rozwiązań dopuszczalnych i zbioru dostępnych zmiennych, parametrów i~zbiorów. GECS wykorzystuje gramatykę języka ZIMPL do tworzenia poprawnych składniowo modeli \akronim{MILP} w~języku \akronim{ZIMPL}. W~odróżnieniu od GECS, który wymaga dostarczenia szczegółowych danych wejściowych, takich jak zmienne i przykłady dopuszczalne, w~przedstawianym w niniejszej pracy systemie na wejściu wystarczający jest opis problemu PL zapisany w języku naturalnym, co eliminuje konieczność posiadania wiedzy eksperckiej do sformułowania problemu. Ponadto, system zaprezentowany w tej pracy jest bardziej przyjazny laikom, umożliwiając im tworzenie modeli PL bez konieczności głębokiego zrozumienia matematycznego sformułowania problemu. 

Powyższy przykład to jeden z wielu metod syntezy modeli programowania matematycznego. W tym kontekście można także wyróżnić podejście \textit{Syntax-guided program synthesis (SyGuS)} \cite{6679385}, polega ono na generowaniu modeli optymalizacyjnych wykorzystując wcześniej zdefiniowaną gramatykę oraz późniejszym sprawdzeniu poprawności wygenerowanych modeli.

Istnieje również grupa metod: \akronim {ESOCCS} (Evolutionary Strategy-based One Class Constraint Synthesis)\cite{PAWLAK2019335}, textit{CMA-ESOCCS} \cite{10.1145/3377930.3389807}, które to syntetyzują ograniczenia \textit{PL} oraz nieliniowego programowania \akronim{NLP} korzystając wyłącznie z przykładów stanów dopuszczalnych \english{feasible states}.

Inne podejście zaproponowano w \cite{LOMBARDI2017343}, gdzie przedstawiono metodologię \english{Empirical Model Learning, EML}. Jej celem jest wykorzystanie modeli uczenia maszynowego, takich jak drzewa decyzyjne i sztuczne sieci neuronowe, do wspomagania konstrukcji modeli optymalizacyjnych.

W \cite{LOMBARDI2017343}, przedstawiono metodologię \english{Empirical Model Learning, EML}. Wykorzystano techniki uczenia maszynowego \english{machine learning} w celu pozyskania komponentów, korzystając z predykcyjnych modeli.

W podobnym celu powstał \textit{IncaLP} \cite{8995380}, który łączy kodowanie problemu dwuklasowego o zbiorach dopuszczalnych oraz niedopuszczalnych w postaci \textit{MILP} z uczeniem inkrementalnym \english{incremental learning}. \textit{IncaLP} skupia się jednak wyłącznie na ograniczeniach problemu.

Model Seeker \cite{10.1007/978-3-642-33558-7_13} identyfikuje ograniczenia w \akronim{CP} wyrażone w języku Prolog, korzystając z jednoklasowego zbioru treningowego oraz napisanej biblioteki fragmentów kodu zawierających ograniczenia. Ogranicza to jego wykorzystanie wyłącznie do dostępnych ograniczeń. Podobnie opracowanie De Raedt i in. \cite{de2018learning} przedstawia przegląd technik związanych z syntezą ograniczeń. Podkreśla to kluczową rolę struktury dostępnych ograniczeń, która jest ważnym czynnikiem przy generowaniu modeli.

Powyższy przegląd wskazuje, iż w dalszym ciągu istnieje możliwość usprawnienia procedur automatycznego tworzenia i weryfikacji modeli PL, w szczególności przy użyciu różnych rodzajów danych wejściowych.

\section{Duże modele językowe dla generowania kodu}

W pracy \cite{10.1145/3695988} zebrano oraz przeanalizowano 395 artykułów naukowych opublikowanych od stycznia 2017 roku do stycznia 2024 roku korzystających z \textit{DMJ} w dziedzinie inżynierii oprogramowania \textit{LLM4SE}. Pozwoliło uzyskać odpowiedź na cztery postawione pytania badawcze. Skategoryzowano różne \textit{DMJ} oraz scharakteryzowano ich właściwości oraz sposób użycia w zadaniach z dziedziny inżynierii oprogramowania \english{Software Engineering, SE}. Efektem jest podział modeli na kategorie według ich architektury. Przedstawiono strategie użycia danych, sposób ich gromadzenia oraz przygotowywania. Zwrócono uwagę na istotę odpowiedniego doboru danych, szczególnie przy zadaniach związanych z kodem źródłowym. Zagłębiają się w strategie optymalizacji oraz oceny wydajności \akronim{DMJ} w \akronim{SE}. Badania wykazały, iż dla większości zadań przy których wykorzystano \textit{DMJ} takich jak: generacja kodu, analiza kodu oraz naprawa programów nie jest wymagany dodatkowe dostrajanie modelu \english{fine-tuning} w danej dziedzinie. Obecne modele \akronim{DMJ} ogólnego przeznaczenia dobrze radzą sobie z powyższymi zadaniami. Jednak aby wykorzystać pełen potencjał \akronim{DMJ} dostrajanie jest zalecane. Według badań równie istotna jest inżynieria podpowiedzi \english{prompt engineering}. Podejście to pozwala na bezproblemowe zintegrowanie \textit{DMJ} w kolejne zadania z danej dziedziny bez konieczności aktualizowania jego parametrów.

Niektóre implementacje \akronim{DMJ} takie jak \textit{ChatGPT} obecnie obsługują komercyjne języki modelowania, np.:~\akronim{AMPL} \cite{ampl_chatgpt_guide}. Wymaga to jednak posiadania licencji na ich użytkowanie. 
Przedstawione w niniejszej pracy rozwiązanie wykorzystuje język programowania \akronim{ZIMPL}, który jest darmowy i~otwartoźródłowy. Wybór \akronim{ZIMPL} pozwala uniknąć dodatkowych kosztów licencyjnych, jednocześnie umożliwiając budowę skalowalnych modeli optymalizacyjnych. Dzięki otwartemu kodowi źródłowemu, \akronim{ZIMPL} może być również, w razie potrzeby, dostosowany do konkretnych potrzeb projektowych co zwiększa jego elastyczność.
