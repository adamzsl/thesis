
\chapter{Dyskusja}

\section{Zalety rozwiązania}

Przedstawione rozwiązanie usprawnia proces generacji modeli \textit{PL}, korzystając z \textit{DMJ} na podstawie opisów słownych. Umożliwia to korzystanie z zalet \textit{PL} dla użytkowników oraz przedsiębiorców, usprawniając tym samym proces optymalizacji rozwiązań. Korzystanie z narzędzia nie wymaga wiedzy eksperckiej z dziedziny optymalizacji. Zaletą tego rozwiązania jest solidne podejście do generacji modeli wykorzystując \textit{DMJ} oraz wiedze ekspercką, zmniejszając tym zauważalnie ilość błędów generowanych przez \textit{DMJ} niekorzystających z powyższych udogodnień. Przekłada się to bezpośrednio na mniejsze koszta uzyskania rozwiązania oraz braku konieczności posiadania wykwalifikowanego personelu w tej dziedzinie. Umożliwia to na rozpowszechnienie ogólnodostępnego rozwiązania w dziedzinie \textit{PL}. 

\section{Wady rozwiązania}
Stworzone narzędzie jest najbardziej wydajne dla prostych instancji problemów \textit{PL} z małą do średniej ilości danych. Przy większej ilości danych \textit{DMJ} może nie działać na satysfakcjonującym poziomie. Wydajność \textit{DMJ} znacząco spada, w miarę wzrostu wielkości kontekstu wejściowego, nawet w przypadku modeli zaprojektowanych do obsługi dużych kontekstów. Rozmiar kontekstu \textit{DMJ}, jest bardzo ograniczony w porównaniu do problemów optymalizacyjnych korzystających z dużej ilości danych wejściowych. \cite{10.1162/tacl_a_00638} Kolejnym ograniczeniem jest zależność pomiędzy jakością generowanego kodu \textit{PL}, a niską różnorodnością dostępnych przykładów w literaturze. Im większa różnorodność dostępnych przykładów w literaturze, tym większa jakość generowanego kodu \textit{PL}.

\section{Poprawa rozwiązania}
Niewątpliwie automatyzacja procesu \textit{uczenia przez wzmacnianie} pozwoliłaby uzyskać bardziej satysfakcjonujące wyniki, pozwalając modelowi dostosować się do bardziej różnorodnych problemów na podstawie nowych oraz wykorzystanych danych. Rozwiązanie zautomatyzowane zostało przedstawione w sekcji \ref{sec:optimus}. 

Zwiększenie ilości oraz różnorodności przykładów również przyczyniłoby się do zwiększenia jakości generowanych modeli \textit{PL}. Jest to rozwiązanie czasochłonne, ponieważ ilość powszechnie dostępnych, profesjonalnych źródeł jest ograniczona.
Hipoteza: Automatyzacja procesu \textit{uczenia przez wzmacnianie} oraz zwiększenie bazy przykładów przyczyniłoby się do poprawy wyników programu.

\section{Trudności}

Początkowo zaczęto tworzyć własny model na jednym z rozwiązań niekomercyjnych metodą \textit{ang. fine-tuningu}. Wydajność tego rozwiązania okazała się niesatysfakcjonująca. Wydajność nie poprawiła się, pomimo zwielokrotnienia bazy przykładów uczących.

Spojrzeć na rozwiązanie wysokopoziomowe, co jest dobre, co jest złe, co można poprawić (postawić hipotezy jak postawić), dlaczego pewnych rzeczy nie da się zrobić (np. duże problemy PL, ograniczenia językowe, etc), odnieść się do innych projektów – co nam nie pomogło, co pomogło, czemu wykorzystaliśmy dane rzeczy

Rozpatrzono użycie różnych \textit{DMJ}, biorąc przy tym pod uwagę najlepszą jakość, przy jak najmniejszym koszcie. Zdecydowaliśmy się na model \texttt{GPT-4o}, odrzucając przy tym modele bardziej wydajne, ze względu na zbyt wysokie koszta obliczeniowe. Skutkiem tej decyzji była konieczność zmiany struktury rozwiązania na bardziej złożoną, co nie jest optymalnym podejściem, gdyż prowadzi do obniżenia przejrzystości oraz zwiększeniu stopniu skomplikowania implementacji.